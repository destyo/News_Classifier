{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUNEF MUCD 2021/2022\n",
    "## News Classification\n",
    "Autor:  \n",
    "- Antonio Tello Gómez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Deployment Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will simulate the deployment of the model. In this hypothetical scenario, we receive a CSV file with 30 news and we return another CSV file with the result of the model predictions, ideally, we would do this automatically. However, we will do it manually and test if the model would work in such an environment. To this end, we will generate a new dataset with fake and real news and then use the pipeline with the model to preprocess and predict the new data. Then we will save the predictions and evaluate the model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle \n",
    "\n",
    "#Functionalities\n",
    "import requests\n",
    "import os\n",
    "import sys\n",
    "import openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "#NLP\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "#Model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from src.Preprocessor import TextPreprocessor\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Métrics\n",
    "from sklearn.metrics import (roc_curve, roc_auc_score, f1_score , confusion_matrix, recall_score, \n",
    "                             precision_score, classification_report, precision_recall_curve, accuracy_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of a New Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Fake News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://python.plainenglish.io/create-ai-content-generator-with-python-flask-and-openai-gpt-3-407a19f096b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to generate fake news using the OpenAI API. Two options:\n",
    " 1. (Supervised) Generate fake news manually with implausible stories related to topics in the original data\n",
    " 2. (Unsupervised) Generate fake news programatically using the Topics extracted from Topic Modeling or most frequent Entities in NER.  \n",
    " \n",
    "With option 2 you can generate a virtually infinite amount of fake news. However, they can be very realisitic and plausibile.  \n",
    "Therefore, I will use option 1. In Which I make sure news are very implausible i.e. fake. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro = 'Write a fake news article about'\n",
    "fn1 = f\"{intro} Obama becoming a dicatator in 2016\"\n",
    "fn2 = f\"{intro} Trump becoming a dicatator in 2016\"\n",
    "fn3 = f\"{intro} Hillary Clinton bombing the white house\"\n",
    "fn4 = f\"{intro} Iran invading the US\"\n",
    "fn5 = f\"{intro} Fbi closing down Fox News\"\n",
    "fn6 = f\"{intro} Ted Cruz becomin muslim\"\n",
    "fn7 = f\"{intro} Donald Trump leading a Mexican Cartel\"\n",
    "fn8 = f\"{intro} Bernie Sanders working for Putin\"\n",
    "fn9 = f\"{intro} Russia hacking the US 2016 elections\"\n",
    "fn10 = f\"{intro} Russia fighting China in 2016\"\n",
    "fn11 = f\"{intro} Soros buying CNN\"\n",
    "fn12 = f\"{intro} Hillary Clinton and Donald Trump having an affair\"\n",
    "fn13 = f\"{intro} ISIS leader calls for American Muslim voters to support Hillary Clinton\"\n",
    "fn14 = f\"{intro} Hillary Clnton and Pizzagate\"\n",
    "fn15 = f\"{intro} Donald Trump and Obama having an affair\"\n",
    "fn16 = f\"{intro} Trump Offering Free One-Way Tickets to Mexico for Those Who Wanna Leave America\"\n",
    "fn17 = f\"{intro} President Obama Confirms He Will Refuse To Leave Office If Trump Is Elected\"\n",
    "fn18 = f\"{intro} Trump declaring war to North Korea\"\n",
    "fn19 = f\"{intro} Soross becoming president\"\n",
    "fn20 = f\"{intro} Obama occupying the withe house\"\n",
    "fn21 = f\"{intro} Mexico president resigning\"\n",
    "fn22 = f\"{intro} Mexico and Canada leaving NAFTA\"\n",
    "fn23 = f\"{intro} Obama becoming president of Canada\"\n",
    "fn24 = f\"{intro} wikileaks and Foxnews\"\n",
    "fn25 = f\"{intro} Putin resigning\"\n",
    "fn26 = f\"{intro} Mexico building thier own wall\"\n",
    "fn27 = f\"{intro} Obama going to jail for corruption\"\n",
    "fn28 = f\"{intro} Republican Party starting civil war\"\n",
    "fn29 = f\"{intro} DonalTrump switching to Democratic Party\"\n",
    "fn30 = f\"{intro} Hillary Clinton switching to Republican Party\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news = [fn1, fn2, fn3, fn4, fn5, fn6, fn7, fn8, fn9, fn10, fn11, fn12, fn13, fn14, fn15, fn16, fn17, fn18, fn19, fn20, fn21, fn22, fn23, fn24, fn25, fn26, fn27, fn28, fn29, fn30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows =  []\n",
    "for fn in fake_news:\n",
    "    response = openai.Completion.create(\n",
    "    engine=\"davinci-instruct-beta-v3\",\n",
    "    prompt=fn,\n",
    "    temperature=0.7,\n",
    "    max_tokens=2000,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0)\n",
    "    rows.append(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news = pd.DataFrame(rows, columns=[\"full_text\"])\n",
    "fake_news[\"label\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news.to_csv(\"../data/new_data/fake_news.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Real News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the NewsApi api to get Real News. Unfortunately, the free version does not allow to retrieve historical news or the full text. Hence, we are going to have a dataset with a lot of tokens out of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_contents(filename):\n",
    "    \"\"\" Given a filename,\n",
    "        return the contents of that file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            return f.read().strip()\n",
    "    except FileNotFoundError:\n",
    "        print(\"'%s' file not found\" % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = get_file_contents('../.apikey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = (f'https://newsapi.org/v2/everything?q=2016+elections&sortBy=popularity&apiKey={key}')\n",
    "url2 = (f'https://newsapi.org/v2/everything?q=Clintons&sortBy=popularity&apiKey={key}')\n",
    "url3 = (f'https://newsapi.org/v2/everything?q=Obama&sortBy=popularity&apiKey={key}')\n",
    "url4 = (f'https://newsapi.org/v2/everything?q=Ted+Cruz&sortBy=popularity&apiKey={key}')\n",
    "url5 = (f'https://newsapi.org/v2/everything?q=november+2016&sortBy=popularity&apiKey={key}')\n",
    "url6 = (f'https://newsapi.org/v2/everything?q=white+house&sortBy=popularity&apiKey={key}')\n",
    "url7 = (f'https://newsapi.org/v2/everything?q=president&sortBy=popularity&apiKey={key}')\n",
    "url8 = (f'https://newsapi.org/v2/everything?q=bernie6&sortBy=popularity&apiKey={key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [url1, url2, url3, url4, url5, url6, url7, url8]\n",
    "jsons = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, url in enumerate(urls): \n",
    "    r = requests.get(url)\n",
    "    jsons[\"json{}\".format(idx)] = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for json in jsons.values():\n",
    "    for article in json['articles']:\n",
    "        rows.append([article[\"title\"], article[\"description\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_news = pd.DataFrame(rows, columns=[\"title\", \"description\"])\n",
    "real_news[\"full_text\"] = real_news[\"title\"] +\" \"+ real_news[\"description\"]\n",
    "real_news[\"label\"] = 0\n",
    "real_news.drop(['title','description'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_news.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_news= real_news[real_news[\"full_text\"].str.contains(\"Trump|Clinton|Obama|Cruz|Elections|Bernie|president\")].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(real_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_news.to_csv(\"../data/new_data/real_news.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news = pd.read_csv(\"../data/new_data/fake_news.csv\")\n",
    "real_news = pd.read_csv(\"../data/new_data/real_news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([fake_news, real_news], ignore_index=True)\n",
    "df = df.sample(frac=1, random_state=2022).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nPresident Donald Trump has been elected to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analysis: Why you can't rely on Trump to help ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump endorses Vance in Ohio's Republican Sena...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\nAccording to sources, Iran has invaded the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\nRussia and China have been in a heated bat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  label\n",
       "0  \\n\\nPresident Donald Trump has been elected to...      1\n",
       "1  Analysis: Why you can't rely on Trump to help ...      0\n",
       "2  Trump endorses Vance in Ohio's Republican Sena...      0\n",
       "3  \\n\\nAccording to sources, Iran has invaded the...      1\n",
       "4  \\n\\nRussia and China have been in a heated bat...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['full_text']\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = pickle.load(open('../models/' + 'optim_lgbm' + '.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = lgbm.predict(X)\n",
    "ypred_proba= lgbm.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({\"full_text\": X, \"label\": ypred, \"probability\": ypred_proba[:,1]})\n",
    "predictions.to_csv(\"../data/new_data/predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(ytest, ypred, ypred_proba = None):\n",
    "    if ypred_proba is not None:\n",
    "        print('ROC-AUC score of the model: {}'.format(roc_auc_score(ytest, ypred_proba[:, 1])))\n",
    "    print('Accuracy of the model: {}\\n'.format(accuracy_score(ytest, ypred)))\n",
    "    print('Classification report: \\n{}\\n'.format(classification_report(ytest, ypred)))\n",
    "    print('Confusion matrix: \\n{}\\n'.format(confusion_matrix(ytest, ypred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score of the model: 0.47444444444444445\n",
      "Accuracy of the model: 0.4666666666666667\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.33      0.38        30\n",
      "           1       0.47      0.60      0.53        30\n",
      "\n",
      "    accuracy                           0.47        60\n",
      "   macro avg       0.46      0.47      0.46        60\n",
      "weighted avg       0.46      0.47      0.46        60\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "[[10 20]\n",
      " [12 18]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(y,ypred, ypred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is not able to generalize outside the dataset it was originally trained on. This might be because the dataset is too small or how it was labeled. Therefore, we would not deploy this model in a real-world scenario.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "115e7b4be8b202d8681536be4587d690d40232cbe799889ab736e9ee853895af"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
