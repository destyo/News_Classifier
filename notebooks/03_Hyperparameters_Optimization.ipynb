{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUNEF MUCD 2021/2022\n",
    "## News Classification\n",
    "Autor:  \n",
    "- Antonio Tello GÃ³mez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "\n",
    "#Functionalities\n",
    "from collections import Counter\n",
    "import sys, os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#NLP\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "# Custom Transformer\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from src.Preprocessor import TextPreprocessor\n",
    "\n",
    "# Models\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(ytest, ypred, ypred_proba = None):\n",
    "    if ypred_proba is not None:\n",
    "        print('ROC-AUC score of the model: {}'.format(roc_auc_score(ytest, ypred_proba[:, 1])))\n",
    "    print('Accuracy of the model: {}\\n'.format(accuracy_score(ytest, ypred)))\n",
    "    print('Classification report: \\n{}\\n'.format(classification_report(ytest, ypred)))\n",
    "    print('Confusion matrix: \\n{}\\n'.format(confusion_matrix(ytest, ypred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = pd.read_csv('../data/train/X_train.csv')['full_text']\n",
    "ytrain = pd.read_csv('../data/train/y_train.csv')['label']\n",
    "xtest = pd.read_csv('../data/test/X_test.csv')['full_text']\n",
    "ytest = pd.read_csv('../data/test/y_test.csv')['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    (\"preprocessor\", TextPreprocessor()),\n",
    "    (\"vectorizer\", TfidfVectorizer()),\n",
    "    (\"clf\", LGBMClassifier(random_state=2022))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters for lightgbm\n",
    "params = {\n",
    "    \"preprocessor__remove_numbers\": [True, False],\n",
    "    \"vectorizer__ngram_range\": [(1, 1), (1, 2), (1,3)],\n",
    "    #\"vectorizer__max_features\": [None, 5000, 10000, 50000],\n",
    "    #\"vectorizer__use_idf\": [True, False],\n",
    "    #\"vectorizer__smooth_idf\": [True, False],\n",
    "    \"vectorizer__min_df\": [0.01],\n",
    "    \"vectorizer__max_df\": [0.995],\n",
    "    \"vectorizer__norm\": [\"l1\", \"l2\"],\n",
    "    'clf__learning_rate': [0.1, 0.05], \n",
    "    #'clf__n_estimators' : [200, 300, 400], \n",
    "    'clf__importance_type' : ['split']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "CPU times: total: 1min 24s\n",
      "Wall time: 12min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor', TextPreprocessor()),\n",
       "                                       ('vectorizer', TfidfVectorizer()),\n",
       "                                       ('clf',\n",
       "                                        LGBMClassifier(random_state=2022))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'clf__importance_type': ['split'],\n",
       "                         'clf__learning_rate': [0.1, 0.05],\n",
       "                         'preprocessor__remove_numbers': [True, False],\n",
       "                         'vectorizer__max_df': [0.995],\n",
       "                         'vectorizer__min_df': [0.01],\n",
       "                         'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'vectorizer__norm': ['l1', 'l2']},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lgbm = GridSearchCV(pipe, params, n_jobs=-1, verbose=1, cv=5, scoring='accuracy')\n",
    "lgbm.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__importance_type: 'split'\n",
      "\tclf__learning_rate: 0.1\n",
      "\tpreprocessor__remove_numbers: False\n",
      "\tvectorizer__max_df: 0.995\n",
      "\tvectorizer__min_df: 0.01\n",
      "\tvectorizer__ngram_range: (1, 2)\n",
      "\tvectorizer__norm: 'l2'\n"
     ]
    }
   ],
   "source": [
    "best_parameters = lgbm.best_estimator_.get_params()\n",
    "for param_name in sorted(params.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lgbm, open('../models/' + 'optim_lgbm' + '.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = pickle.load(open('../models/' + 'optim_lgbm' + '.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 14.8 s\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ypred = lgbm.predict(xtest)\n",
    "ypred_proba = lgbm.predict_proba(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score of the model: 0.9860422175471104\n",
      "Accuracy of the model: 0.9435637285986049\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94       789\n",
      "           1       0.94      0.95      0.94       788\n",
      "\n",
      "    accuracy                           0.94      1577\n",
      "   macro avg       0.94      0.94      0.94      1577\n",
      "weighted avg       0.94      0.94      0.94      1577\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "[[741  48]\n",
      " [ 41 747]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(ytest,ypred, ypred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting Threshold "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the advantages of the LightGBMClassifier compared to the SGDClassifier (with loss hinge) is that we can predict probabilities and hence, play with the threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Geometric Mean or G-Mean is a metric for imbalanced classification that, if optimized, will seek a balance between the sensitivity and the specificity.  \n",
    "G-Mean = sqrt(Sensitivity * Specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.525891, G-Mean=0.945\n",
      "ROC-AUC score of the model: 0.9860422175471104\n",
      "Accuracy of the model: 0.9448319594166138\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94       789\n",
      "           1       0.94      0.95      0.94       788\n",
      "\n",
      "    accuracy                           0.94      1577\n",
      "   macro avg       0.94      0.94      0.94      1577\n",
      "weighted avg       0.94      0.94      0.94      1577\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "[[745  44]\n",
      " [ 43 745]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# keep probabilities for the positive outcome only\n",
    "yhat = ypred_proba[:, 1]\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(ytest, yhat)\n",
    "\n",
    "gmeans = np.sqrt(tpr * (1-fpr))\n",
    "# locate the index of the largest g-mean\n",
    "ix = np.argmax(gmeans)\n",
    "print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\n",
    "\n",
    "ypred_new_threshold = (ypred_proba[:,1]>thresholds[ix]).astype(int)\n",
    "evaluate_model(ytest,ypred_new_threshold,ypred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    (\"preprocessor\", TextPreprocessor()),\n",
    "    (\"vectorizer\", TfidfVectorizer()),\n",
    "    (\"clf\", SGDClassifier(random_state=2022))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters for sgd\n",
    "params = {\n",
    "    #\"preprocessor__remove_numbers\": [True, False],      #Removing numbers does not improve score\n",
    "    \"vectorizer__min_df\": [0.005],\n",
    "    \"vectorizer__max_df\": [0.995],\n",
    "    \"vectorizer__ngram_range\": [(1, 1), (1, 2), (1,3)],\n",
    "    \"vectorizer__norm\": [\"l1\", \"l2\"],\n",
    "    \"clf__alpha\": [0.0001, 0.001],\n",
    "    \"clf__penalty\": [\"l2\", \"elasticnet\"],\n",
    "    \"clf__loss\": [\"hinge\", \"log\", \"squared_hinge\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "CPU times: total: 52.6 s\n",
      "Wall time: 22min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor', TextPreprocessor()),\n",
       "                                       ('vectorizer', TfidfVectorizer()),\n",
       "                                       ('clf',\n",
       "                                        SGDClassifier(random_state=2022))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'clf__alpha': [0.0001, 0.001],\n",
       "                         'clf__loss': ['hinge', 'log', 'squared_hinge'],\n",
       "                         'clf__penalty': ['l2', 'elasticnet'],\n",
       "                         'vectorizer__max_df': [0.995],\n",
       "                         'vectorizer__min_df': [0.005],\n",
       "                         'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'vectorizer__norm': ['l1', 'l2']},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sgd = GridSearchCV(pipe, params, n_jobs=-1, verbose=1, cv=5, scoring='accuracy')\n",
    "sgd.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__alpha: 0.0001\n",
      "\tclf__loss: 'hinge'\n",
      "\tclf__penalty: 'elasticnet'\n",
      "\tvectorizer__max_df: 0.995\n",
      "\tvectorizer__min_df: 0.005\n",
      "\tvectorizer__ngram_range: (1, 3)\n",
      "\tvectorizer__norm: 'l2'\n"
     ]
    }
   ],
   "source": [
    "best_parameters = sgd.best_estimator_.get_params()\n",
    "for param_name in sorted(params.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(sgd, open('../models/' + 'optim_sgd' + '.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = pickle.load(open('../models/' + 'optim_sgd' + '.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 9.06 s\n",
      "Wall time: 9.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ypred = sgd.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 0.9441978440076094\n",
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94       789\n",
      "           1       0.94      0.95      0.94       788\n",
      "\n",
      "    accuracy                           0.94      1577\n",
      "   macro avg       0.94      0.94      0.94      1577\n",
      "weighted avg       0.94      0.94      0.94      1577\n",
      "\n",
      "\n",
      "Confusion matrix: \n",
      "[[741  48]\n",
      " [ 40 748]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(ytest,ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will move forward with the LightGBMClassifier even though it has a slightly lower accuracy it gives us more flexibility as we can play with the threshold."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "115e7b4be8b202d8681536be4587d690d40232cbe799889ab736e9ee853895af"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
